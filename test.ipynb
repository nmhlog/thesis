{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "\n",
    "data_folder = os.path.join('Synthetic_v3_InstanceSegmentation')\n",
    "files = sorted(glob.glob(data_folder + '/*.txt'))\n",
    "numclass = 15\n",
    "semanticIDs = []\n",
    "for i in range(numclass):\n",
    "    semanticIDs.append(i)\n",
    "\n",
    "class_numpoint_mean_dict = {}\n",
    "class_radius_mean = {}\n",
    "for semanticID in semanticIDs:\n",
    "    class_numpoint_mean_dict[semanticID] = []\n",
    "    class_radius_mean[semanticID] = []\n",
    "num_points_semantic = np.array([0 for i in range(numclass)])\n",
    "\n",
    "for file in files:\n",
    "    data_buff = np.loadtxt(file,delimiter=\",\")\n",
    "    coords, colors, sem_labels, instance_labels =data_buff[:,:3],data_buff[:,3:6],data_buff[:,-2],data_buff[:,-1]\n",
    "    points = np.concatenate((coords,colors,np.expand_dims(sem_labels.astype(int),axis=1),np.expand_dims(instance_labels.astype(int),axis=1)),axis=1)\n",
    "    for semanticID in semanticIDs:\n",
    "        singleSemantic = points[np.where(points[:,6]==semanticID)]\n",
    "        uniqueInstances, counts = np.unique(singleSemantic[:,7], return_counts=True)\n",
    "        for count in counts:\n",
    "            class_numpoint_mean_dict[semanticID].append(count)\n",
    "        allRadius = []\n",
    "        for uniqueInstance in uniqueInstances:\n",
    "            eachInstance = singleSemantic[np.where(singleSemantic[:,7]==uniqueInstance)]\n",
    "            radius = (np.max(eachInstance,axis=0) - np.min(eachInstance,axis=0))/2\n",
    "            radius = math.sqrt(radius[0]**2 + radius[1]**2 + radius[2]**2)\n",
    "            class_radius_mean[semanticID].append(radius)\n",
    "\n",
    "    uniqueSemantic,semanticCount = np.unique(points[:,6],return_counts=True)\n",
    "    uniqueSemanticCount = np.array([0 for i in range(numclass)])\n",
    "    uniqueSemantic = uniqueSemantic.astype(int)\n",
    "    indexOf100 = np.where(uniqueSemantic == -100)\n",
    "    semanticCount = np.delete(semanticCount, indexOf100)\n",
    "    uniqueSemantic = np.delete(uniqueSemantic, indexOf100)\n",
    "    uniqueSemanticCount[uniqueSemantic] = semanticCount\n",
    "    num_points_semantic += uniqueSemanticCount\n",
    "\n",
    "class_numpoint_mean_list = []\n",
    "class_radius_mean_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the printed list in hierarchical_aggregation.cpp for class_numpoint_mean_dict: \n",
      "[1.0, 10355.0, 59.0, 124.0, 1334.0, 161.0, 425.0, 1081.0, 450.0, 26.0, 43.0, 61.0, 40.0, 109.0, 1308.0]\n",
      "Using the printed list in hierarchical_aggregation.cu for class_radius_mean: \n",
      "[1.0, 19.79, 3.02, 3.36, 8.45, 2.99, 4.36, 10.56, 4.91, 3.69, 1.64, 5.83, 3.22, 2.5, 16.67]\n",
      "Using the printed list in hais_run_stpls3d.yaml for class_weight\n",
      "[1.0, 1.0, 300.43, 160.92, 1.76, 26.16, 34.13, 156.68, 172.63, 392.34, 106.22, 88.87, 297.43, 72.74, 21.56]\n"
     ]
    }
   ],
   "source": [
    "for semanticID in semanticIDs:\n",
    "    class_numpoint_mean_list.append(sum(class_numpoint_mean_dict[semanticID])*1.0/len(class_numpoint_mean_dict[semanticID]))\n",
    "    class_radius_mean_list.append(sum(class_radius_mean[semanticID])/len(class_radius_mean[semanticID]))\n",
    "\n",
    "print (\"Using the printed list in hierarchical_aggregation.cpp for class_numpoint_mean_dict: \")\n",
    "print ([1.0]+[float(\"{0:0.0f}\".format(i)) for i in class_numpoint_mean_list][1:], sep=',')\n",
    "print (\"Using the printed list in hierarchical_aggregation.cu for class_radius_mean: \")\n",
    "print ([1.0]+[float(\"{0:0.2f}\".format(i)) for i in class_radius_mean_list][1:], sep='')\n",
    "\n",
    "### make ground to 1 the make building to 1\n",
    "maxSemantic = np.max(num_points_semantic)\n",
    "num_points_semantic = maxSemantic/num_points_semantic\n",
    "num_points_semantic = num_points_semantic/num_points_semantic[1]\n",
    "print (\"Using the printed list in hais_run_stpls3d.yaml for class_weight\")\n",
    "print ([1.0,1.0]+[float(\"{0:0.2f}\".format(i)) for i in num_points_semantic][2:], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berbeda masalah. \n",
    "Using the printed list in hierarchical_aggregation.cpp for class_numpoint_mean_dict: \n",
    "[1.0, 10355.0, 59.0, 124.0, 1334.0, 161.0, 425.0, 1081.0, 450.0, 26.0, 43.0, 61.0, 40.0, 109.0, 1308.0]\n",
    "Using the printed list in hierarchical_aggregation.cu for class_radius_mean: \n",
    "[1.0, 19.79, 3.02, 3.36, 8.45, 2.99, 4.36, 10.56, 4.91, 3.69, 1.64, 5.83, 3.22, 2.5, 16.67]\n",
    "Using the printed list in hais_run_stpls3d.yaml for class_weight\n",
    "[1.0, 1.0, 300.43, 160.92, 1.76, 26.16, 34.13, 156.68, 172.63, 392.34, 106.22, 88.87, 297.43, 72.74, 21.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.loadtxt(\"Synthetic_v3_InstanceSegmentation/1_points_GTv3.txt\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yang sali\n",
    "Using the printed list in hierarchical_aggregation.cpp for class_numpoint_mean_dict: \n",
    "[1.0, 4121.0, 53.0, 115.0, 1013.0, 141.0, 363.0, 777.0, 360.0, 23.0, 40.0, 56.0, 35.0, 100.0, 605.0]\n",
    "Using the printed list in hierarchical_aggregation.cu for class_radius_mean: \n",
    "[1.0, 12.87, 2.02, 2.67, 7.46, 2.73, 3.88, 7.84, 4.13, 2.22, 1.5, 5.2, 2.47, 2.24, 10.28]\n",
    "Using the printed list in hais_run_stpls3d.yaml for class_weight\n",
    "[1.0, 1.0, 50.71, 27.48, 1.39, 20.51, 25.37, 45.42, 60.12, 79.72, 85.26, 64.34, 73.18, 13.35, 17.37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/media/nmhlog/Naufal Disk/Thesis Experiment/thesis/test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nmhlog/Naufal%20Disk/Thesis%20Experiment/thesis/test.ipynb#ch0000006?line=0'>1</a>\u001b[0m class_numpoint_mean_dict[\u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m*\u001b[39m\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(class_numpoint_mean_dict[\u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "class_numpoint_mean_dict[\"0\"]*1.0/len(class_numpoint_mean_dict[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4105.001702946838"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(class_numpoint_mean_dict[1])/len(class_numpoint_mean_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10408"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85938aeac5d3fc666b9772978340405759206969cda94d8472987c4123c8d935"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('thesis-lib': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
