{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, math, numpy as np\n",
    "import scipy.ndimage\n",
    "import scipy.interpolate\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from util.config import cfg\n",
    "from util.log import logger\n",
    "from lib.hais_ops.functions import hais_ops\n",
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, test=False):\n",
    "        self.data_root = cfg.data_root\n",
    "        self.dataset = cfg.dataset\n",
    "        self.filename_suffix = cfg.filename_suffix\n",
    "\n",
    "        self.batch_size = cfg.batch_size\n",
    "        self.train_workers = cfg.train_workers\n",
    "        self.val_workers = cfg.train_workers\n",
    "\n",
    "        self.full_scale = cfg.full_scale\n",
    "        self.scale = cfg.scale\n",
    "        self.max_npoint = cfg.max_npoint\n",
    "        self.mode = cfg.mode\n",
    "\n",
    "        self.train_split = getattr(cfg, 'train_split', 'train')\n",
    "\n",
    "        if test:\n",
    "            self.test_split = cfg.split  # val or test\n",
    "            self.test_workers = cfg.test_workers\n",
    "            cfg.batch_size = 1\n",
    "\n",
    "\n",
    "    def trainLoader(self):\n",
    "        if self.train_split == 'trainval':\n",
    "            train_file_names = sorted(glob.glob(os.path.join(self.data_root, self.dataset, 'train', '*' + self.filename_suffix))\n",
    "                + glob.glob(os.path.join(self.data_root, self.dataset, 'val', '*' + self.filename_suffix))\n",
    "            )\n",
    "        elif self.train_split == 'train':\n",
    "            train_file_names = sorted(glob.glob(os.path.join(self.data_root, self.dataset, 'train', '*' + self.filename_suffix)))\n",
    "        else:\n",
    "            raise Exception\n",
    "\n",
    "        self.train_files = [torch.load(i) for i in train_file_names]\n",
    "\n",
    "        logger.info('Training samples: {}'.format(len(self.train_files)))\n",
    "\n",
    "        train_set = list(range(len(self.train_files)))\n",
    "        self.train_data_loader = DataLoader(train_set, batch_size=self.batch_size, collate_fn=self.trainMerge, num_workers=self.train_workers,\n",
    "                                            shuffle=True, sampler=None, drop_last=True, pin_memory=True)\n",
    "        \n",
    "\n",
    "    def dist_trainLoader(self):\n",
    "        train_file_names = sorted(glob.glob(os.path.join(self.data_root, self.dataset, 'train', '*' + self.filename_suffix)))\n",
    "        self.train_files = [torch.load(i) for i in train_file_names]\n",
    "\n",
    "        logger.info('Training samples: {}'.format(len(self.train_files)))\n",
    "\n",
    "        train_set = list(range(len(self.train_files)))\n",
    "        # self.train_data_loader = DataLoader(train_set, batch_size=self.batch_size, collate_fn=self.trainMerge, num_workers=self.train_workers,\n",
    "        #                                     shuffle=True, sampler=None, drop_last=True, pin_memory=True)\n",
    "        \n",
    "        # world_size = dist.get_world_size()\n",
    "        # rank = dist.get_rank()\n",
    "        # self.data_sampler = torch.utils.data.distributed.DistributedSampler(train_set, num_replicas=world_size, rank=rank)\n",
    "        self.data_sampler = torch.utils.data.distributed.DistributedSampler(train_set)\n",
    "\n",
    "        self.train_data_loader = DataLoader(train_set, batch_size=self.batch_size, \n",
    "                                    collate_fn=self.trainMerge, \n",
    "                                    num_workers=self.train_workers,\n",
    "                                    shuffle=False, sampler=self.data_sampler, \n",
    "                                    drop_last=False, pin_memory=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def valLoader(self):\n",
    "        val_file_names = sorted(glob.glob(os.path.join(self.data_root, self.dataset, 'val', '*' + self.filename_suffix)))\n",
    "        self.val_files = [torch.load(i) for i in val_file_names]\n",
    "\n",
    "        logger.info('Validation samples: {}'.format(len(self.val_files)))\n",
    "\n",
    "        val_set = list(range(len(self.val_files)))\n",
    "        self.val_data_loader = DataLoader(val_set, batch_size=self.batch_size, collate_fn=self.valMerge, num_workers=self.val_workers,\n",
    "                                          shuffle=False, drop_last=False, pin_memory=True)\n",
    "\n",
    "\n",
    "    def testLoader(self):\n",
    "        self.test_file_names = sorted(glob.glob(os.path.join(self.data_root, self.dataset, self.test_split, '*' + self.filename_suffix)))\n",
    "        self.test_files = [torch.load(i) for i in self.test_file_names]\n",
    "\n",
    "        logger.info('Testing samples ({}): {}'.format(self.test_split, len(self.test_files)))\n",
    "\n",
    "        test_set = list(np.arange(len(self.test_files)))\n",
    "        self.test_data_loader = DataLoader(test_set, batch_size=1, collate_fn=self.testMerge, num_workers=self.test_workers,\n",
    "                                           shuffle=False, drop_last=False, pin_memory=True)\n",
    "\n",
    "    # Elastic distortion\n",
    "    def elastic(self, x, gran, mag):\n",
    "        blur0 = np.ones((3, 1, 1)).astype('float32') / 3\n",
    "        blur1 = np.ones((1, 3, 1)).astype('float32') / 3\n",
    "        blur2 = np.ones((1, 1, 3)).astype('float32') / 3\n",
    "\n",
    "        bb = np.abs(x).max(0).astype(np.int32)//gran + 3\n",
    "        noise = [np.random.randn(bb[0], bb[1], bb[2]).astype('float32') for _ in range(3)]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur0, mode='constant', cval=0) for n in noise]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur1, mode='constant', cval=0) for n in noise]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur2, mode='constant', cval=0) for n in noise]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur0, mode='constant', cval=0) for n in noise]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur1, mode='constant', cval=0) for n in noise]\n",
    "        noise = [scipy.ndimage.filters.convolve(n, blur2, mode='constant', cval=0) for n in noise]\n",
    "        ax = [np.linspace(-(b-1)*gran, (b-1)*gran, b) for b in bb]\n",
    "        interp = [scipy.interpolate.RegularGridInterpolator(ax, n, bounds_error=0, fill_value=0) for n in noise]\n",
    "        def g(x_):\n",
    "            return np.hstack([i(x_)[:,None] for i in interp])\n",
    "        return x + g(x) * mag\n",
    "\n",
    "\n",
    "    def getInstanceInfo(self, xyz, instance_label):\n",
    "        '''\n",
    "        :param xyz: (n, 3)\n",
    "        :param instance_label: (n), int, (0~nInst-1, -100)\n",
    "        :return: instance_num, dict\n",
    "        '''\n",
    "        instance_info = np.ones((xyz.shape[0], 9), dtype=np.float32) * -100.0   # (n, 9), float, (cx, cy, cz, minx, miny, minz, maxx, maxy, maxz)\n",
    "        instance_pointnum = []   # (nInst), int\n",
    "        instance_num = int(instance_label.max()) + 1\n",
    "        for i_ in range(instance_num):\n",
    "            inst_idx_i = np.where(instance_label == i_)\n",
    "\n",
    "            # instance_info\n",
    "            xyz_i = xyz[inst_idx_i]\n",
    "            min_xyz_i = xyz_i.min(0)\n",
    "            max_xyz_i = xyz_i.max(0)\n",
    "            mean_xyz_i = xyz_i.mean(0)\n",
    "            instance_info_i = instance_info[inst_idx_i]\n",
    "            instance_info_i[:, 0:3] = mean_xyz_i\n",
    "            instance_info_i[:, 3:6] = min_xyz_i\n",
    "            instance_info_i[:, 6:9] = max_xyz_i\n",
    "            instance_info[inst_idx_i] = instance_info_i\n",
    "\n",
    "            # instance_pointnum\n",
    "            instance_pointnum.append(inst_idx_i[0].size)\n",
    "\n",
    "        return instance_num, {\"instance_info\": instance_info, \"instance_pointnum\": instance_pointnum}\n",
    "\n",
    "\n",
    "    def dataAugment(self, xyz, jitter=False, flip=False, rot=False):\n",
    "        m = np.eye(3)\n",
    "        if jitter:\n",
    "            m += np.random.randn(3, 3) * 0.1\n",
    "        if flip:\n",
    "            m[0][0] *= np.random.randint(0, 2) * 2 - 1  # flip x randomly\n",
    "        if rot:\n",
    "            theta = np.random.rand() * 2 * math.pi\n",
    "            m = np.matmul(m, [[math.cos(theta), math.sin(theta), 0], [-math.sin(theta), math.cos(theta), 0], [0, 0, 1]])  # rotation\n",
    "        return np.matmul(xyz, m)\n",
    "\n",
    "\n",
    "    def crop(self, xyz):\n",
    "        '''\n",
    "        :param xyz: (n, 3) >= 0\n",
    "        '''\n",
    "        xyz_offset = xyz.copy()\n",
    "        valid_idxs = (xyz_offset.min(1) >= 0)\n",
    "        assert valid_idxs.sum() == xyz.shape[0]\n",
    "\n",
    "        full_scale = np.array([self.full_scale[1]] * 3)\n",
    "        room_range = xyz.max(0) - xyz.min(0)\n",
    "        while (valid_idxs.sum() > self.max_npoint):\n",
    "            offset = np.clip(full_scale - room_range + 0.001, None, 0) * np.random.rand(3)\n",
    "            xyz_offset = xyz + offset\n",
    "            valid_idxs = (xyz_offset.min(1) >= 0) * ((xyz_offset < full_scale).sum(1) == 3)\n",
    "            full_scale[:2] -= 32\n",
    "\n",
    "        return xyz_offset, valid_idxs\n",
    "\n",
    "\n",
    "    def getCroppedInstLabel(self, instance_label, valid_idxs):\n",
    "        instance_label = instance_label[valid_idxs]\n",
    "        j = 0\n",
    "        while (j < instance_label.max()):\n",
    "            if (len(np.where(instance_label == j)[0]) == 0):\n",
    "                instance_label[instance_label == instance_label.max()] = j\n",
    "            j += 1\n",
    "        return instance_label\n",
    "\n",
    "\n",
    "    def trainMerge(self, id):\n",
    "        locs = []\n",
    "        locs_float = []\n",
    "        feats = []\n",
    "        labels = []\n",
    "        instance_labels = []\n",
    "\n",
    "        instance_infos = []  # (N, 9)\n",
    "        instance_pointnum = []  # (total_nInst), int\n",
    "\n",
    "        batch_offsets = [0]\n",
    "\n",
    "        total_inst_num = 0\n",
    "        for i, idx in enumerate(id):\n",
    "            xyz_origin, rgb, label, instance_label = self.train_files[idx]\n",
    "\n",
    "\n",
    "            # jitter / flip x / rotation\n",
    "            xyz_middle = self.dataAugment(xyz_origin, True, True, True)\n",
    "\n",
    "            # scale\n",
    "            xyz = xyz_middle * self.scale\n",
    "\n",
    "            # elastic\n",
    "            ### 3 here need to be changed to same as scale (STPLS3D)\n",
    "            xyz = self.elastic(xyz, 6 * self.scale // 3, 40 * self.scale / 3)\n",
    "            xyz = self.elastic(xyz, 20 * self.scale // 3, 160 * self.scale / 3)\n",
    "\n",
    "            # offset\n",
    "            xyz -= xyz.min(0)\n",
    "\n",
    "            # crop\n",
    "            xyz, valid_idxs = self.crop(xyz)\n",
    "\n",
    "            xyz_middle = xyz_middle[valid_idxs]\n",
    "            xyz = xyz[valid_idxs]\n",
    "            rgb = rgb[valid_idxs]\n",
    "            label = label[valid_idxs]\n",
    "            instance_label = self.getCroppedInstLabel(instance_label, valid_idxs)\n",
    "\n",
    "            # get instance information\n",
    "            inst_num, inst_infos = self.getInstanceInfo(xyz_middle, instance_label.astype(np.int32))\n",
    "            inst_info = inst_infos[\"instance_info\"]  # (n, 9), (cx, cy, cz, minx, miny, minz, maxx, maxy, maxz)\n",
    "            inst_pointnum = inst_infos[\"instance_pointnum\"]   # (nInst), list\n",
    "\n",
    "            instance_label[np.where(instance_label != -100)] += total_inst_num\n",
    "            total_inst_num += inst_num\n",
    "\n",
    "            # merge the scene to the batch\n",
    "            batch_offsets.append(batch_offsets[-1] + xyz.shape[0])\n",
    "\n",
    "            locs.append(torch.cat([torch.LongTensor(xyz.shape[0], 1).fill_(i), torch.from_numpy(xyz).long()], 1))\n",
    "            locs_float.append(torch.from_numpy(xyz_middle))\n",
    "            feats.append(torch.from_numpy(rgb) + torch.randn(3) * 0.1)\n",
    "            labels.append(torch.from_numpy(label))\n",
    "            instance_labels.append(torch.from_numpy(instance_label))\n",
    "\n",
    "            instance_infos.append(torch.from_numpy(inst_info))\n",
    "            instance_pointnum.extend(inst_pointnum)\n",
    "\n",
    "        # merge all the scenes in the batchd\n",
    "        batch_offsets = torch.tensor(batch_offsets, dtype=torch.int)  # int (B+1)\n",
    "\n",
    "        locs = torch.cat(locs, 0)                                # long (N, 1 + 3), the batch item idx is put in locs[:, 0]\n",
    "        locs_float = torch.cat(locs_float, 0).to(torch.float32)  # float (N, 3)\n",
    "        feats = torch.cat(feats, 0)                              # float (N, C)\n",
    "        labels = torch.cat(labels, 0).long()                     # long (N)\n",
    "        instance_labels = torch.cat(instance_labels, 0).long()   # long (N)\n",
    "\n",
    "        instance_infos = torch.cat(instance_infos, 0).to(torch.float32)       # float (N, 9) (meanxyz, minxyz, maxxyz)\n",
    "        instance_pointnum = torch.tensor(instance_pointnum, dtype=torch.int)  # int (total_nInst)\n",
    "\n",
    "        spatial_shape = np.clip((locs.max(0)[0][1:] + 1).numpy(), self.full_scale[0], None)     # long (3)\n",
    "\n",
    "        # voxelize\n",
    "        voxel_locs, p2v_map, v2p_map = hais_ops.voxelization_idx(locs, self.batch_size, self.mode)\n",
    "\n",
    "        return {'locs': locs, 'voxel_locs': voxel_locs, 'p2v_map': p2v_map, 'v2p_map': v2p_map,\n",
    "                'locs_float': locs_float, 'feats': feats, 'labels': labels, 'instance_labels': instance_labels,\n",
    "                'instance_info': instance_infos, 'instance_pointnum': instance_pointnum,\n",
    "                'id': id, 'offsets': batch_offsets, 'spatial_shape': spatial_shape}\n",
    "\n",
    "\n",
    "    def valMerge(self, id):\n",
    "        locs = []\n",
    "        locs_float = []\n",
    "        feats = []\n",
    "        labels = []\n",
    "        instance_labels = []\n",
    "\n",
    "        instance_infos = []  # (N, 9)\n",
    "        instance_pointnum = []  # (total_nInst), int\n",
    "\n",
    "        batch_offsets = [0]\n",
    "\n",
    "        total_inst_num = 0\n",
    "        for i, idx in enumerate(id):\n",
    "            xyz_origin, rgb, label, instance_label = self.val_files[idx]\n",
    "\n",
    "            # flip x / rotation\n",
    "            xyz_middle = self.dataAugment(xyz_origin, False, False, True)\n",
    "\n",
    "            # scale\n",
    "            xyz = xyz_middle * self.scale\n",
    "\n",
    "            # offset\n",
    "            xyz -= xyz.min(0)\n",
    "\n",
    "            # crop\n",
    "            xyz, valid_idxs = self.crop(xyz)\n",
    "\n",
    "            xyz_middle = xyz_middle[valid_idxs]\n",
    "            xyz = xyz[valid_idxs]\n",
    "            rgb = rgb[valid_idxs]\n",
    "            label = label[valid_idxs]\n",
    "            instance_label = self.getCroppedInstLabel(instance_label, valid_idxs)\n",
    "\n",
    "            # get instance information\n",
    "            inst_num, inst_infos = self.getInstanceInfo(xyz_middle, instance_label.astype(np.int32))\n",
    "            inst_info = inst_infos[\"instance_info\"]  # (n, 9), (cx, cy, cz, minx, miny, minz, maxx, maxy, maxz)\n",
    "            inst_pointnum = inst_infos[\"instance_pointnum\"]  # (nInst), list\n",
    "\n",
    "            instance_label[np.where(instance_label != -100)] += total_inst_num\n",
    "            total_inst_num += inst_num\n",
    "\n",
    "            # merge the scene to the batch\n",
    "            batch_offsets.append(batch_offsets[-1] + xyz.shape[0])\n",
    "\n",
    "            locs.append(torch.cat([torch.LongTensor(xyz.shape[0], 1).fill_(i), torch.from_numpy(xyz).long()], 1))\n",
    "            locs_float.append(torch.from_numpy(xyz_middle))\n",
    "            feats.append(torch.from_numpy(rgb))\n",
    "            labels.append(torch.from_numpy(label))\n",
    "            instance_labels.append(torch.from_numpy(instance_label))\n",
    "\n",
    "            instance_infos.append(torch.from_numpy(inst_info))\n",
    "            instance_pointnum.extend(inst_pointnum)\n",
    "\n",
    "        # merge all the scenes in the batch\n",
    "        batch_offsets = torch.tensor(batch_offsets, dtype=torch.int)  # int (B+1)\n",
    "\n",
    "        locs = torch.cat(locs, 0)                                  # long (N, 1 + 3), the batch item idx is put in locs[:, 0]\n",
    "        locs_float = torch.cat(locs_float, 0).to(torch.float32)    # float (N, 3)\n",
    "        feats = torch.cat(feats, 0)                                # float (N, C)\n",
    "        labels = torch.cat(labels, 0).long()                       # long (N)\n",
    "        instance_labels = torch.cat(instance_labels, 0).long()     # long (N)\n",
    "\n",
    "        instance_infos = torch.cat(instance_infos, 0).to(torch.float32)               # float (N, 9) (meanxyz, minxyz, maxxyz)\n",
    "        instance_pointnum = torch.tensor(instance_pointnum, dtype=torch.int)          # int (total_nInst)\n",
    "\n",
    "        spatial_shape = np.clip((locs.max(0)[0][1:] + 1).numpy(), self.full_scale[0], None)  # long (3)\n",
    "\n",
    "        # voxelize\n",
    "        voxel_locs, p2v_map, v2p_map = hais_ops.voxelization_idx(locs, self.batch_size, self.mode)\n",
    "\n",
    "        return {'locs': locs, 'voxel_locs': voxel_locs, 'p2v_map': p2v_map, 'v2p_map': v2p_map,\n",
    "                'locs_float': locs_float, 'feats': feats, 'labels': labels, 'instance_labels': instance_labels,\n",
    "                'instance_info': instance_infos, 'instance_pointnum': instance_pointnum,\n",
    "                'id': id, 'offsets': batch_offsets, 'spatial_shape': spatial_shape}\n",
    "\n",
    "\n",
    "    def testMerge(self, id):\n",
    "        locs = []\n",
    "        locs_float = []\n",
    "        feats = []\n",
    "\n",
    "        labels = []#\n",
    "\n",
    "        batch_offsets = [0]\n",
    "        for i, idx in enumerate(id):\n",
    "\n",
    "            if self.test_split == 'val':\n",
    "                xyz_origin, rgb, label, instance_label = self.test_files[idx]\n",
    "            elif self.test_split == 'test':\n",
    "                xyz_origin, rgb = self.test_files[idx]\n",
    "            else:\n",
    "                print(\"Wrong test split: {}!\".format(self.test_split))\n",
    "                exit(0)\n",
    "\n",
    "            # flip x / rotation\n",
    "            xyz_middle = self.dataAugment(xyz_origin, False, False, True)\n",
    "\n",
    "            # scale\n",
    "            xyz = xyz_middle * self.scale\n",
    "\n",
    "            # offset\n",
    "            xyz -= xyz.min(0)\n",
    "\n",
    "            # merge the scene to the batch\n",
    "            batch_offsets.append(batch_offsets[-1] + xyz.shape[0])\n",
    "\n",
    "            locs.append(torch.cat([torch.LongTensor(xyz.shape[0], 1).fill_(i), torch.from_numpy(xyz).long()], 1))\n",
    "            locs_float.append(torch.from_numpy(xyz_middle))\n",
    "            feats.append(torch.from_numpy(rgb))\n",
    "\n",
    "            if self.test_split == 'val':\n",
    "                labels.append(torch.from_numpy(label))\n",
    "\n",
    "        if self.test_split == 'val':\n",
    "            labels = torch.cat(labels, 0).long()                     # long (N)\n",
    "\n",
    "        # merge all the scenes in the batch\n",
    "        batch_offsets = torch.tensor(batch_offsets, dtype=torch.int)  # int (B+1)\n",
    "\n",
    "        locs = torch.cat(locs, 0)                                         # long (N, 1 + 3), the batch item idx is put in locs[:, 0]\n",
    "        locs_float = torch.cat(locs_float, 0).to(torch.float32)           # float (N, 3)\n",
    "        feats = torch.cat(feats, 0)                                       # float (N, C)\n",
    "\n",
    "        spatial_shape = np.clip((locs.max(0)[0][1:] + 1).numpy(), self.full_scale[0], None)  # long (3)\n",
    "\n",
    "        # voxelize\n",
    "        voxel_locs, p2v_map, v2p_map = hais_ops.voxelization_idx(locs, self.batch_size, self.mode)\n",
    "\n",
    "        if self.test_split == 'val':\n",
    "            return {'locs': locs, 'voxel_locs': voxel_locs, 'p2v_map': p2v_map, 'v2p_map': v2p_map,\n",
    "                    'locs_float': locs_float, 'feats': feats,\n",
    "                    'id': id, 'offsets': batch_offsets, 'spatial_shape': spatial_shape,\n",
    "                    'labels': labels}\n",
    "        \n",
    "        elif self.test_split == 'test':\n",
    "            return {'locs': locs, 'voxel_locs': voxel_locs, 'p2v_map': p2v_map, 'v2p_map': v2p_map,\n",
    "                    'locs_float': locs_float, 'feats': feats,\n",
    "                    'id': id, 'offsets': batch_offsets, 'spatial_shape': spatial_shape} \n",
    "        else:\n",
    "            assert Exception\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hais_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/media/nmhlog/Naufal Disk/Thesis Experiment/github/thesis/dataloader.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nmhlog/Naufal%20Disk/Thesis%20Experiment/github/thesis/dataloader.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhais_ops\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hais_ops'"
     ]
    }
   ],
   "source": [
    "from hais_ops.functions import hais_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/media/nmhlog/Naufal Disk/Thesis Experiment/github/thesis/HAIS/lib/hais_ops/HAIS_OP.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor5zero_Ev",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/media/nmhlog/Naufal Disk/Thesis Experiment/github/thesis/dataloader.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/nmhlog/Naufal%20Disk/Thesis%20Experiment/github/thesis/dataloader.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nmhlog/Naufal%20Disk/Thesis%20Experiment/github/thesis/dataloader.ipynb#ch0000002?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mHAIS_OP\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /media/nmhlog/Naufal Disk/Thesis Experiment/github/thesis/HAIS/lib/hais_ops/HAIS_OP.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor5zero_Ev"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import HAIS_OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25c5a45234ee30c82512e50b7a36d5d2b36668f405adf48cf8bf23aebcee0967"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dev-thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
